# Project 4: Machine Learning Fairness

### [Project Description](doc/project4_desc.md)

Term: Fall 2023

+ Team 7
+ Projec title: Machine Learning Fairness Algorithm Implementation
+ Team members
	+ Manan Brahmbhatt
	+ Shaohuan Wu
	+ Han Wang
	+ Yihan Zhang
	+ Shefali Shrivastava
+ Project summary: The ProPublica COMPAS dataset uses logistic regression algorithm to predict whether an offender will reoffend within two years, but it create some unfairness impact for different social groups, which puts certain groups at a disadvantage. In this project, we implemented some algorithms of two papers ( A4: Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment (DM and DM-sen), A6: Handling Conditional Discrimination (LM and LPS)), which can reduce the unfairness impact for certain types of people while guarantee the prediction accuracy, so as to ensure that the machine learning algorithm is more fair.
	
**Contribution statement**: [default] All team members contributed equally in all stages of this project. Shaohuan Wu and Manan Brahmbhatt worked on reading and producing the results and report for A4: Disparate Mistreatment. Han Wang, Yihan Zhang and Shefali Shrivastava worked on reading and producing the results and report for A6: Handling Conditional Discrimination.

Following [suggestions](http://nicercode.github.io/blog/2013-04-05-projects/) by [RICH FITZJOHN](http://nicercode.github.io/about/#Team) (@richfitz). This folder is orgarnized as follows.

```
proj/
├── lib/
├── data/
├── doc/
├── figs/
└── output/
```

Please see each subfolder for a README file.
