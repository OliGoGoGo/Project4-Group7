{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b086ca",
   "metadata": {},
   "source": [
    "## Load The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d22be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv(\"/Users/fiona/Documents/GitHub/Project4-Group7/data/compas-scores-two-years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1a31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data['id'] == 8867]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11378a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recidivated rate for Caucasian = 39.36%\n",
      "recidivated rate for African-American = 51.43%\n"
     ]
    }
   ],
   "source": [
    "df_C = data[data['race'] == 'Caucasian']\n",
    "df_A = data[data['race'] == 'African-American']\n",
    "\n",
    "C_rate = df_C['two_year_recid'].sum()/df_C.shape[0]\n",
    "A_rate = df_A['two_year_recid'].sum()/df_A.shape[0]\n",
    "\n",
    "print(f'recidivated rate for Caucasian = {round(C_rate*100, 2)}%')\n",
    "print(f'recidivated rate for African-American = {round(A_rate*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d70c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA = pd.concat([df_C, df_A])\n",
    "df_CA.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df_CA_2 = df_CA.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861e4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_CA['two_year_recid']\n",
    "s = df_CA['race']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649db72b",
   "metadata": {},
   "source": [
    "## PARTITION Function (Algorithm 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e93f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PARTITION(df, exp_attr):\n",
    "    # Find all unique value for the explanatory attribute e\n",
    "    case_lst = list(set(df[exp_attr]))\n",
    "    # Create an empty dictionary to store the partitioned dataframe\n",
    "    X_dict = {}\n",
    "    \n",
    "    for case in case_lst:\n",
    "        temp_df = df[df[exp_attr] == case]\n",
    "        temp_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        X_dict[case] = temp_df\n",
    "    \n",
    "    return X_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ad3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column \"decile_score\" is chosen to be the explanatory attribute e\n",
    "dic_partition = PARTITION(df_CA, exp_attr = 'decile_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c48fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>elizabeth thieme</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>thieme</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>Female</td>\n",
       "      <td>1976-06-03</td>\n",
       "      <td>39</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>2014-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>kortney coleman</td>\n",
       "      <td>kortney</td>\n",
       "      <td>coleman</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Female</td>\n",
       "      <td>1978-08-22</td>\n",
       "      <td>37</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>craig gilbert</td>\n",
       "      <td>craig</td>\n",
       "      <td>gilbert</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>1968-06-14</td>\n",
       "      <td>47</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>russell sottile</td>\n",
       "      <td>russell</td>\n",
       "      <td>sottile</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-10</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>mark friedland</td>\n",
       "      <td>mark</td>\n",
       "      <td>friedland</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>1960-07-27</td>\n",
       "      <td>55</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>2013-12-29</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              name      first       last compas_screening_date     sex  \\\n",
       "0  10  elizabeth thieme  elizabeth     thieme            2014-03-16  Female   \n",
       "1  16   kortney coleman    kortney    coleman            2013-01-01  Female   \n",
       "2  19     craig gilbert      craig    gilbert            2013-10-30  Female   \n",
       "3  32   russell sottile    russell    sottile            2013-01-25    Male   \n",
       "4  45    mark friedland       mark  friedland            2013-12-30    Male   \n",
       "\n",
       "          dob  age          age_cat       race  ...  v_decile_score  \\\n",
       "0  1976-06-03   39          25 - 45  Caucasian  ...               1   \n",
       "1  1978-08-22   37          25 - 45  Caucasian  ...               1   \n",
       "2  1968-06-14   47  Greater than 45  Caucasian  ...               1   \n",
       "3  1973-01-10   43          25 - 45  Caucasian  ...               2   \n",
       "4  1960-07-27   55  Greater than 45  Caucasian  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
       "1           Low        2013-01-01  2013-01-01   2013-01-02               0   \n",
       "2           Low        2013-10-30  2014-06-03   2014-11-19               1   \n",
       "3           Low        2013-01-25  2013-01-24   2013-01-25               1   \n",
       "4           Low        2013-12-30  2013-12-29   2013-12-31               0   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     2   747     0              0  \n",
       "1     1  1186     0              0  \n",
       "2     0   216     1              1  \n",
       "3     0  1162     0              0  \n",
       "4     1   823     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_partition[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ee4fe",
   "metadata": {},
   "source": [
    "## DELTA Function (Algorithm 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eaf160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DELTA(dic_partition):\n",
    "    # Create an empty dictionary to store the delta value for each race under each decile_score\n",
    "    dic_delta = {}\n",
    "    for key, df in dic_partition.items():\n",
    "        # Crerate another empty dictionary to store the delta value for each race\n",
    "        dic_C_A = {}\n",
    "        \n",
    "        # Create temporary dataframe for different race group\n",
    "        temp_df_C = df[df['race'] == 'Caucasian']\n",
    "        temp_df_A = df[df['race'] == 'African-American']\n",
    "        \n",
    "        # Obtain the number of people in different races, respectively\n",
    "        G_C = temp_df_C.shape[0]\n",
    "        G_A = temp_df_A.shape[0]\n",
    "        \n",
    "        # Calculate p⋆(+|ei) according to equation 4 in the paper\n",
    "        prob_C = temp_df_C['two_year_recid'].sum() / G_C\n",
    "        prob_A = temp_df_A['two_year_recid'].sum() / G_A\n",
    "        prob_star = (prob_C + prob_A) / 2\n",
    "        \n",
    "        # Compute the absolute difference according to the formula in the pseudo-code of Algorithm 4\n",
    "        diff_prob_C = abs(prob_C - prob_star)\n",
    "        diff_prob_A = abs(prob_A - prob_star)\n",
    "        \n",
    "        # Store the values for two race groups\n",
    "        dic_C_A['Caucasian'] = int(round(G_C * diff_prob_C, 0))\n",
    "        dic_C_A['African-American'] = int(round(G_A * diff_prob_A, 0))\n",
    "        \n",
    "        # Store the resulted dictionary dic_C_A to the larger one (dic_delta)\n",
    "        dic_delta[key] = dic_C_A\n",
    "        \n",
    "    return dic_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605eaf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'Caucasian': 7, 'African-American': 4},\n",
       " 2: {'Caucasian': 2, 'African-American': 2},\n",
       " 3: {'Caucasian': 11, 'African-American': 14},\n",
       " 4: {'Caucasian': 9, 'African-American': 12},\n",
       " 5: {'Caucasian': 3, 'African-American': 4},\n",
       " 6: {'Caucasian': 1, 'African-American': 2},\n",
       " 7: {'Caucasian': 2, 'African-American': 5},\n",
       " 8: {'Caucasian': 2, 'African-American': 7},\n",
       " 9: {'Caucasian': 1, 'African-American': 3},\n",
       " 10: {'Caucasian': 3, 'African-American': 13}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DELTA(dic_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17892a5",
   "metadata": {},
   "source": [
    "## Internal Ranker (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5658c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bce7f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranker_log_reg(df):\n",
    "    # Mannually select useful columns that can be utilized in logistic regression\n",
    "    useful_col = ['sex', 'age', 'juv_fel_count', 'decile_score', 'juv_misd_count', \n",
    "              'juv_other_count', 'priors_count', 'c_charge_degree',\n",
    "              'is_recid', 'is_violent_recid', 'v_decile_score', 'event']\n",
    "    X = df[useful_col]\n",
    "    # Use one-hot encoding to trasnfer two variables so that it can be put into the regression model\n",
    "    X = pd.get_dummies(X, columns = ['sex', 'c_charge_degree'], drop_first = True, dtype = int)\n",
    "    \n",
    "    # Obtain the label column\n",
    "    y = df['two_year_recid']\n",
    "    \n",
    "    # Fit the logistic the logistic regression model with iteration time 1000 so that the model can converge\n",
    "    logistic_reg = LogisticRegression(max_iter = 1000)\n",
    "    logistic_reg.fit(X, y)\n",
    "    \n",
    "    # Obtain the probabilities for each observation\n",
    "    proba = logistic_reg.predict_proba(X)\n",
    "    \n",
    "    # Obtain the probability of categorizing to 1 for each observation\n",
    "    prob_1_lst = []\n",
    "    for i in range(proba.shape[0]):\n",
    "        prob_1_lst.append(proba[i][1])\n",
    "    \n",
    "    return prob_1_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0e271",
   "metadata": {},
   "source": [
    "## Local Massaging (Algorithm 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916cdb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_massaging(df, s = 'race', e = 'decile_score', y = 'two_year_recid'):\n",
    "    \n",
    "    # Apply Algorithm 3 \n",
    "    dic_partition = PARTITION(df, exp_attr = e)\n",
    "    \n",
    "    # Apply Algorithm 4\n",
    "    dic_delta = DELTA(dic_partition)\n",
    "    \n",
    "    # Extract each partition X^(i)\n",
    "    for key, df_part in dic_partition.items():\n",
    "        # learn a ranker (logistic regression)\n",
    "        df_part['ranker'] = ranker_log_reg(df_part)\n",
    "        \n",
    "        # Find the people with race Caucasian\n",
    "        temp_df_C = df_part[df_part['race'] == 'Caucasian']\n",
    "        # Sort the Caucasian table according to the ranker from largest to lowest\n",
    "        sorted_df_C = temp_df_C.sort_values(by = 'ranker', ascending = False)\n",
    "        # Obtain the number of people needed to be adjusted\n",
    "        adj_num_C = dic_delta[key]['Caucasian']\n",
    "        # Find the rows with probability (ranker) smaller than the threshold\n",
    "        # The threshold should be adjusted\n",
    "        sub_sorted_df_C = sorted_df_C[sorted_df_C['ranker'] < 0.5]\n",
    "        # Obtain the list of id for the rows from previous steps\n",
    "        sub_id_C = list(sub_sorted_df_C.id)\n",
    "        # Find the id that needed to be adjusted using the result of DELTA function\n",
    "        change_id_C = sub_id_C[:adj_num_C]\n",
    "        # Change the label for specific rows\n",
    "        # Labels are changed from 0 to 1 since Caucasian have lower rate of two_year_recid\n",
    "        for id_num in change_id_C:\n",
    "            df.loc[df['id'] == id_num, 'two_year_recid'] = 1\n",
    "        \n",
    "        # Similar process is performed as above\n",
    "        temp_df_A = df_part[df_part['race'] == 'African-American']\n",
    "        sorted_df_A = temp_df_A.sort_values(by = 'ranker', ascending = True)\n",
    "        adj_num_A = dic_delta[key]['African-American']\n",
    "        sub_sorted_df_A = sorted_df_A[sorted_df_A['ranker'] > 0.5]\n",
    "        sub_id_A = list(sub_sorted_df_A.id)\n",
    "        change_id_A = sub_id_A[:adj_num_A]\n",
    "        # Labels are changed from 1 to 0 since African-American have higher rate of two_year_recid\n",
    "        for id_num in change_id_A:\n",
    "            df.loc[df['id'] == id_num, 'two_year_recid'] = 0\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33fad770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>edward riddle</td>\n",
       "      <td>edward</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>1974-07-23</td>\n",
       "      <td>41</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>elizabeth thieme</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>thieme</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>Female</td>\n",
       "      <td>1976-06-03</td>\n",
       "      <td>39</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>2014-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>bo bradac</td>\n",
       "      <td>bo</td>\n",
       "      <td>bradac</td>\n",
       "      <td>2013-11-04</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994-06-10</td>\n",
       "      <td>21</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-04</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>benjamin franc</td>\n",
       "      <td>benjamin</td>\n",
       "      <td>franc</td>\n",
       "      <td>2013-11-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988-06-01</td>\n",
       "      <td>27</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-11-26</td>\n",
       "      <td>2013-11-25</td>\n",
       "      <td>2013-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>kortney coleman</td>\n",
       "      <td>kortney</td>\n",
       "      <td>coleman</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Female</td>\n",
       "      <td>1978-08-22</td>\n",
       "      <td>37</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>10994</td>\n",
       "      <td>jarred payne</td>\n",
       "      <td>jarred</td>\n",
       "      <td>payne</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>Male</td>\n",
       "      <td>1985-07-31</td>\n",
       "      <td>30</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>10995</td>\n",
       "      <td>raheem smith</td>\n",
       "      <td>raheem</td>\n",
       "      <td>smith</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-06-28</td>\n",
       "      <td>20</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id              name      first     last compas_screening_date  \\\n",
       "0         8     edward riddle     edward   riddle            2014-02-19   \n",
       "1        10  elizabeth thieme  elizabeth   thieme            2014-03-16   \n",
       "2        13         bo bradac         bo   bradac            2013-11-04   \n",
       "3        14    benjamin franc   benjamin    franc            2013-11-26   \n",
       "4        16   kortney coleman    kortney  coleman            2013-01-01   \n",
       "...     ...               ...        ...      ...                   ...   \n",
       "6145  10994      jarred payne     jarred    payne            2014-05-10   \n",
       "6146  10995      raheem smith     raheem    smith            2013-10-20   \n",
       "6147  10996     steven butler     steven   butler            2013-11-23   \n",
       "6148  10997   malcolm simmons    malcolm  simmons            2014-02-01   \n",
       "6149  11000       farrah jean     farrah     jean            2014-03-09   \n",
       "\n",
       "         sex         dob  age       age_cat              race  ...  \\\n",
       "0       Male  1974-07-23   41       25 - 45         Caucasian  ...   \n",
       "1     Female  1976-06-03   39       25 - 45         Caucasian  ...   \n",
       "2       Male  1994-06-10   21  Less than 25         Caucasian  ...   \n",
       "3       Male  1988-06-01   27       25 - 45         Caucasian  ...   \n",
       "4     Female  1978-08-22   37       25 - 45         Caucasian  ...   \n",
       "...      ...         ...  ...           ...               ...  ...   \n",
       "6145    Male  1985-07-31   30       25 - 45  African-American  ...   \n",
       "6146    Male  1995-06-28   20  Less than 25  African-American  ...   \n",
       "6147    Male  1992-07-17   23  Less than 25  African-American  ...   \n",
       "6148    Male  1993-03-25   23  Less than 25  African-American  ...   \n",
       "6149  Female  1982-11-17   33       25 - 45  African-American  ...   \n",
       "\n",
       "      v_decile_score  v_score_text  v_screening_date  in_custody  out_custody  \\\n",
       "0                  2           Low        2014-02-19  2014-03-31   2014-04-18   \n",
       "1                  1           Low        2014-03-16  2014-03-15   2014-03-18   \n",
       "2                  5        Medium        2013-11-04  2015-01-06   2015-01-07   \n",
       "3                  4           Low        2013-11-26  2013-11-25   2013-11-26   \n",
       "4                  1           Low        2013-01-01  2013-01-01   2013-01-02   \n",
       "...              ...           ...               ...         ...          ...   \n",
       "6145               2           Low        2014-05-10  2015-10-22   2015-10-22   \n",
       "6146               9          High        2013-10-20  2014-04-07   2014-04-27   \n",
       "6147               5        Medium        2013-11-23  2013-11-22   2013-11-24   \n",
       "6148               5        Medium        2014-02-01  2014-01-31   2014-02-02   \n",
       "6149               2           Low        2014-03-09  2014-03-08   2014-03-09   \n",
       "\n",
       "      priors_count.1 start   end event two_year_recid  \n",
       "0                 14     5    40     1              1  \n",
       "1                  0     2   747     0              0  \n",
       "2                  1     0   428     1              1  \n",
       "3                  0     0   857     0              0  \n",
       "4                  0     1  1186     0              0  \n",
       "...              ...   ...   ...   ...            ...  \n",
       "6145               0     0   529     1              1  \n",
       "6146               0     0   169     0              0  \n",
       "6147               0     1   860     0              0  \n",
       "6148               0     1   790     0              0  \n",
       "6149               3     0   754     0              0  \n",
       "\n",
       "[6150 rows x 53 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_massaging(df_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4de2c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [8867, 8223, 9352]\n",
    "# df[df['id'] == 8867]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1776200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recidivated rate for Caucasian = 41.04%\n",
      "recidivated rate for African-American = 50.03%\n"
     ]
    }
   ],
   "source": [
    "df_C_2 = df_CA[df_CA['race'] == 'Caucasian']\n",
    "df_A_2 = df_CA[df_CA['race'] == 'African-American']\n",
    "\n",
    "C_rate_2 = df_C_2['two_year_recid'].sum()/df_C.shape[0]\n",
    "A_rate_2 = df_A_2['two_year_recid'].sum()/df_A.shape[0]\n",
    "\n",
    "print(f'recidivated rate for Caucasian = {round(C_rate_2*100, 2)}%')\n",
    "print(f'recidivated rate for African-American = {round(A_rate_2*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c061e",
   "metadata": {},
   "source": [
    "## Local Preferential Sampling (Algorithm 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905bf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_pref_samp(df, s = 'race', e = 'decile_score', y = 'two_year_recid'):\n",
    "    \n",
    "    # Apply Algorithm 3 \n",
    "    dic_partition = PARTITION(df, exp_attr = e)\n",
    "    \n",
    "    # Apply Algorithm 4\n",
    "    dic_delta = DELTA(dic_partition)\n",
    "    \n",
    "    # Extract each partition X^(i)\n",
    "    for key, df_part in dic_partition.items():\n",
    "        # learn a ranker (logistic regression)\n",
    "        df_part['ranker'] = ranker_log_reg(df_part)\n",
    "        \n",
    "        temp_df_C = df_part[df_part['race'] == 'Caucasian']\n",
    "        sorted_df_C = temp_df_C.sort_values(by = 'ranker', ascending = False)\n",
    "        # Find the value of DELTA(Caucasian)/2\n",
    "        adj_num_C = int(round(dic_delta[key]['Caucasian']/2, 0))\n",
    "        \n",
    "        # delete DELTA(Caucasian)/2 (less Caucasian with label 0)\n",
    "        sub_sorted_df_C_1 = sorted_df_C[sorted_df_C['ranker'] < 0.5]\n",
    "        sub_id_C_1 = list(sub_sorted_df_C_1.id)\n",
    "        ids_to_delete_C = sub_id_C_1[:adj_num_C]\n",
    "        df = df.drop(df[df['id'].isin(ids_to_delete_C)].index)\n",
    "        \n",
    "        # duplicate DELTA(Caucasian)/2 (more Caucasian with label 1)\n",
    "        sub_sorted_df_C_2 = sorted_df_C[sorted_df_C['ranker'] > 0.5]\n",
    "        sub_id_C_2 = list(sub_sorted_df_C_2.id)\n",
    "        if adj_num_C > 0:\n",
    "            ids_to_dup_C = sub_id_C_2[-adj_num_C:]\n",
    "        else:\n",
    "            ids_to_dup_C = []\n",
    "        rows_to_duplicate_C = df[df['id'].isin(ids_to_dup_C)]\n",
    "        df = pd.concat([df, rows_to_duplicate_C], ignore_index = True)\n",
    "        \n",
    "        \n",
    "        temp_df_A = df_part[df_part['race'] == 'African-American']\n",
    "        sorted_df_A = temp_df_A.sort_values(by = 'ranker', ascending = False)\n",
    "        # Find the value of DELTA(African-American)/2\n",
    "        adj_num_A = int(round(dic_delta[key]['African-American']/2, 0))\n",
    "        \n",
    "        # delete DELTA(African-American)/2 (less African-American with label 1)\n",
    "        sub_sorted_df_A_1 = sorted_df_A[sorted_df_A['ranker'] > 0.5]\n",
    "        sub_id_A_1 = list(sub_sorted_df_A_1.id)\n",
    "        ids_to_delete_A = sub_id_A_1[:adj_num_A]\n",
    "        df = df.drop(df[df['id'].isin(ids_to_delete_A)].index)\n",
    "        \n",
    "        # duplicate DELTA(African-American)/2 (more African-American with label 0)\n",
    "        sub_sorted_df_A_2 = sorted_df_A[sorted_df_A['ranker'] < 0.5]\n",
    "        sub_id_A_2 = list(sub_sorted_df_A_2.id)\n",
    "        if adj_num_A > 0:\n",
    "            ids_to_dup_A = sub_id_A_2[-adj_num_A:]\n",
    "        else:\n",
    "            ids_to_dup_A = []\n",
    "        rows_to_duplicate_A = df[df['id'].isin(ids_to_dup_A)]\n",
    "        df = pd.concat([df, rows_to_duplicate_A], ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f6093ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = local_pref_samp(df_CA_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b894e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recidivated rate for Caucasian = 40.06%\n",
      "recidivated rate for African-American = 50.57%\n"
     ]
    }
   ],
   "source": [
    "df_C_3 = new[new['race'] == 'Caucasian']\n",
    "df_A_3 = new[new['race'] == 'African-American']\n",
    "\n",
    "C_rate_3 = df_C_3['two_year_recid'].sum()/df_C_2.shape[0]\n",
    "A_rate_3 = df_A_3['two_year_recid'].sum()/df_A_2.shape[0]\n",
    "\n",
    "print(f'recidivated rate for Caucasian = {round(C_rate_3*100, 2)}%')\n",
    "print(f'recidivated rate for African-American = {round(A_rate_3*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a20c07",
   "metadata": {},
   "source": [
    "## Colclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194e3dd",
   "metadata": {},
   "source": [
    "Based on the reuslts above, we can observe that the difference between the recidivated rate for two groups of people becomes smaller when we using the method of local massaging. Thus, local massaging may be a better choice in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
